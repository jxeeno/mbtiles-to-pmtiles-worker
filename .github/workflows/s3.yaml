name: S3 Workflow

on:
  workflow_dispatch: 
    inputs:
      key:
        description: 'Key'
        required: true
        default: 'ABSPOA.mbtiles'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
    steps:
      - name: Maximize build space
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 512
          swap-size-mb: 1024
          remove-dotnet: 'true'
      - name: Checkout
        uses: actions/checkout@v2
      - name: 'Install pmtiles'
        run: |
          pip install pmtiles
      - name: 'Convert mbtiles'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          INPUT_FILENAME: ${{ github.event.inputs.key }}
        run: |
          export OUTPUT_FILENAME="$(echo $INPUT_FILENAME | sed 's/.mbtiles//').pmtiles"
          echo "Summary: This action downloads $INPUT_FILENAME from S3, converts to pmtiles and and uploads as $OUTPUT_FILENAME"
          echo "Status: Downloading $INPUT_FILENAME from S3"
          time aws s3api get-object --bucket $S3_BUCKET_NAME --endpoint-url $S3_ENDPOINT_URL --key $INPUT_FILENAME in.mbtiles
          echo "Status: Downloaded $INPUT_FILENAME from S3"
          ls -lah
          echo "Status: Converting $INPUT_FILENAME to $OUTPUT_FILENAME"
          time pmtiles-convert in.mbtiles out.pmtiles
          echo "Status: PMTiles conversion completed"
          ls -lah
          echo "Status: Uploading $OUTPUT_FILENAME to S3"
          time aws s3api put-object --bucket $S3_BUCKET_NAME --endpoint-url $S3_ENDPOINT_URL --key $OUTPUT_FILENAME --body out.pmtiles
          echo "Status: Uploaded $OUTPUT_FILENAME to S3"
